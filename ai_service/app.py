#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
AIæ¨¡æ‹Ÿæ³•åº­æœåŠ¡
æä¾›HTTPæ¥å£ä¾›åç«¯è°ƒç”¨
"""

import os
import sys
from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import requests
import json
import threading
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from court_debate_sdk import CourtDebateModel

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…¨å±€æ¨¡å‹å®ä¾‹
_model = None
_model_lock = False

# æ¨¡å‹åˆå§‹åŒ–çŠ¶æ€
_model_init_status = {
    'initializing': False,
    'loaded': False,
    'error': None,
    'progress': '',
    'progress_steps': []
}
_model_init_lock = threading.Lock()

# å¤–éƒ¨AI APIé…ç½®
EXTERNAL_AI_API_KEY = "sk-aslsGiKSQWdlPmXad3StwEY1BEJFpjh4wAwLEWlxUltcNqfi"
EXTERNAL_AI_BASE_URL = "https://chatapi.zjt66.top/v1"
EXTERNAL_AI_MODEL = "gpt-4o-mini"


def resolve_model_path(adapter_dir: str) -> str:
    """è§£ææ¨¡å‹è·¯å¾„ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„"""
    # å¦‚æœæ˜¯ç»å¯¹è·¯å¾„ï¼Œç›´æ¥è¿”å›
    if os.path.isabs(adapter_dir):
        if not os.path.exists(adapter_dir):
            raise FileNotFoundError(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {adapter_dir}")
        return adapter_dir
    
    # ç›¸å¯¹è·¯å¾„ï¼šå°è¯•å¤šä¸ªå¯èƒ½çš„ä½ç½®ï¼ˆå»é‡ï¼‰
    # ä¼˜å…ˆæ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•ï¼Œå› ä¸ºæ¨¡å‹ç›®å½•åº”è¯¥åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹
    script_dir = os.path.dirname(os.path.abspath(__file__))  # ai_service ç›®å½•
    project_root = os.path.dirname(script_dir)  # é¡¹ç›®æ ¹ç›®å½• D:\MootAI
    current_work_dir = os.getcwd()
    
    # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„è·¯å¾„ï¼ˆå»é‡ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
    candidate_paths = []
    path_labels = []
    
    # 1. é¡¹ç›®æ ¹ç›®å½•ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œæ¨¡å‹ç›®å½•åº”è¯¥åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼‰
    project_root_path = os.path.join(project_root, adapter_dir)
    project_root_path_abs = os.path.abspath(project_root_path)
    if project_root_path_abs not in candidate_paths:
        candidate_paths.append(project_root_path_abs)
        path_labels.append(f"é¡¹ç›®æ ¹ç›®å½• ({project_root})")
    
    # 2. å½“å‰å·¥ä½œç›®å½•
    current_dir_path = os.path.abspath(adapter_dir)
    if current_dir_path not in candidate_paths:
        candidate_paths.append(current_dir_path)
        path_labels.append(f"å½“å‰å·¥ä½œç›®å½• ({current_work_dir})")
    
    # 3. ai_service ç›®å½•ï¼ˆè„šæœ¬æ‰€åœ¨ç›®å½•ï¼‰
    script_dir_path = os.path.join(script_dir, adapter_dir)
    script_dir_path_abs = os.path.abspath(script_dir_path)
    if script_dir_path_abs not in candidate_paths:
        candidate_paths.append(script_dir_path_abs)
        path_labels.append(f"è„šæœ¬æ‰€åœ¨ç›®å½• ({script_dir})")
    
    # ä¾æ¬¡æ£€æŸ¥æ¯ä¸ªè·¯å¾„
    for path in candidate_paths:
        if os.path.exists(path):
            return path
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼ŒæŠ›å‡ºé”™è¯¯ï¼ˆæ˜¾ç¤ºå»é‡åçš„è·¯å¾„ï¼‰
    error_msg = f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹ç›®å½• '{adapter_dir}'\n\n"
    error_msg += "å·²å°è¯•ä»¥ä¸‹ä½ç½®ï¼š\n"
    for i, (path, label) in enumerate(zip(candidate_paths, path_labels), 1):
        error_msg += f"  {i}. {label}\n     â†’ {path}\n"
    
    error_msg += "\n" + "="*60 + "\n"
    error_msg += "è§£å†³æ–¹æ¡ˆï¼š\n\n"
    error_msg += "æ–¹æ¡ˆ1ï¼šå°†æ¨¡å‹ç›®å½•æ”¾åˆ°ä»¥ä¸‹ä»»ä¸€ä½ç½®ï¼š\n"
    for path in candidate_paths[:2]:  # åªæ˜¾ç¤ºå‰ä¸¤ä¸ªæ¨èä½ç½®
        error_msg += f"  â€¢ {path}\n"
    
    error_msg += "\næ–¹æ¡ˆ2ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šæ¨¡å‹ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼š\n"
    error_msg += "  Windows: set ADAPTER_DIR=D:\\path\\to\\court_debate_model\n"
    error_msg += "  Linux/Mac: export ADAPTER_DIR=/path/to/court_debate_model\n"
    
    error_msg += "\næ–¹æ¡ˆ3ï¼šåœ¨å¯åŠ¨è„šæœ¬ä¸­è®¾ç½®ï¼ˆæ¨èï¼‰ï¼š\n"
    error_msg += "  ç¼–è¾‘ ai_service/start_service.batï¼Œä¿®æ”¹ ADAPTER_DIR ç¯å¢ƒå˜é‡\n"
    
    error_msg += "\næ³¨æ„ï¼šæ¨¡å‹ç›®å½•å¿…é¡»åŒ…å« adapter_config.json æ–‡ä»¶ã€‚\n"
    error_msg += "="*60
    
    raise FileNotFoundError(error_msg)


def update_init_progress(step, message):
    """æ›´æ–°æ¨¡å‹åˆå§‹åŒ–è¿›åº¦"""
    global _model_init_status
    with _model_init_lock:
        _model_init_status['progress'] = message
        if step not in _model_init_status['progress_steps']:
            _model_init_status['progress_steps'].append(step)
        logger.info(f"[æ¨¡å‹åˆå§‹åŒ–] {message}")


def init_model_async():
    """åœ¨åå°çº¿ç¨‹ä¸­åˆå§‹åŒ–æ¨¡å‹"""
    global _model, _model_lock, _model_init_status
    
    with _model_init_lock:
        if _model is not None:
            _model_init_status['loaded'] = True
            _model_init_status['initializing'] = False
            return
        if _model_init_status['initializing']:
            return
        _model_init_status['initializing'] = True
        _model_init_status['loaded'] = False
        _model_init_status['error'] = None
        _model_init_status['progress'] = ''
        _model_init_status['progress_steps'] = []
    
    def load_model():
        global _model, _model_lock, _model_init_status
        try:
            update_init_progress('start', 'æ­£åœ¨åŠ è½½AIæ¨¡å‹...')
            
            adapter_dir_env = os.getenv("ADAPTER_DIR", "court_debate_model")
            
            # è§£ææ¨¡å‹è·¯å¾„
            adapter_dir = resolve_model_path(adapter_dir_env)
            update_init_progress('path_resolved', f'ä½¿ç”¨æ¨¡å‹ç›®å½•: {adapter_dir}')
            
            load_in_4bit = os.getenv("LOAD_IN_4BIT", "true").lower() == "true"
            gpu_id = int(os.getenv("GPU_ID", "0"))
            
            update_init_progress('config', f'é…ç½®: 4bité‡åŒ–={load_in_4bit}, GPU={gpu_id}')
            
            # å¼€å§‹åŠ è½½æ¨¡å‹ï¼ˆè¿™ä¸€æ­¥ä¼šèŠ±è´¹å¾ˆé•¿æ—¶é—´ï¼Œæˆ‘ä»¬æ·»åŠ æ›´å¤šè¿›åº¦ç‚¹ï¼‰
            update_init_progress('loading_tokenizer', 'æ­£åœ¨åŠ è½½tokenizer...')
            
            _model_lock = True
            _model = CourtDebateModel(
                adapter_dir=adapter_dir,
                load_in_4bit=load_in_4bit,
                gpu_id=gpu_id
            )
            
            # æ¨¡å‹åŠ è½½å®Œæˆåï¼Œæ›´æ–°è¿›åº¦
            update_init_progress('model_loaded', 'æ¨¡å‹åŠ è½½å®Œæˆï¼Œæ­£åœ¨éªŒè¯...')
            
            # éªŒè¯æ¨¡å‹
            if _model.model is not None and _model.tokenizer is not None:
                update_init_progress('model_verified', 'æ¨¡å‹éªŒè¯å®Œæˆ')
            
            update_init_progress('loaded', 'AIæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼')
            
            with _model_init_lock:
                _model_init_status['loaded'] = True
                _model_init_status['initializing'] = False
                _model_init_status['error'] = None
                
        except Exception as e:
            error_msg = str(e)
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {error_msg}")
            with _model_init_lock:
                _model_init_status['error'] = error_msg
                _model_init_status['initializing'] = False
                _model_init_status['loaded'] = False
            _model_lock = False
        finally:
            _model_lock = False
    
    # åœ¨åå°çº¿ç¨‹ä¸­åŠ è½½æ¨¡å‹
    thread = threading.Thread(target=load_model, daemon=True)
    thread.start()


def get_model():
    """è·å–æ¨¡å‹å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _model, _model_lock
    
    if _model is None and not _model_lock:
        _model_lock = True
        try:
            logger.info("æ­£åœ¨åŠ è½½AIæ¨¡å‹...")
            adapter_dir_env = os.getenv("ADAPTER_DIR", "court_debate_model")
            
            # è§£ææ¨¡å‹è·¯å¾„
            adapter_dir = resolve_model_path(adapter_dir_env)
            logger.info(f"ä½¿ç”¨æ¨¡å‹ç›®å½•: {adapter_dir}")
            
            load_in_4bit = os.getenv("LOAD_IN_4BIT", "true").lower() == "true"
            gpu_id = int(os.getenv("GPU_ID", "0"))
            
            _model = CourtDebateModel(
                adapter_dir=adapter_dir,
                load_in_4bit=load_in_4bit,
                gpu_id=gpu_id
            )
            logger.info("AIæ¨¡å‹åŠ è½½å®Œæˆï¼")
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            _model_lock = False
            raise
        finally:
            _model_lock = False
    
    return _model


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'ok',
        'model_loaded': _model is not None
    })


@app.route('/api/model/init', methods=['POST'])
def init_model():
    """åˆå§‹åŒ–æ¨¡å‹ï¼ˆåå°å¼‚æ­¥åŠ è½½ï¼‰"""
    global _model_init_status
    
    with _model_init_lock:
        if _model is not None:
            return jsonify({
                'success': True,
                'message': 'æ¨¡å‹å·²åŠ è½½',
                'status': 'loaded'
            })
        
        if _model_init_status['initializing']:
            return jsonify({
                'success': True,
                'message': 'æ¨¡å‹æ­£åœ¨åˆå§‹åŒ–ä¸­',
                'status': 'initializing'
            })
    
    # å¯åŠ¨åå°åˆå§‹åŒ–
    init_model_async()
    
    return jsonify({
        'success': True,
        'message': 'æ¨¡å‹åˆå§‹åŒ–å·²å¯åŠ¨',
        'status': 'initializing'
    })


@app.route('/api/model/status', methods=['GET'])
def get_model_status():
    """è·å–æ¨¡å‹åˆå§‹åŒ–çŠ¶æ€"""
    global _model, _model_init_status
    
    with _model_init_lock:
        status = {
            'loaded': _model is not None or _model_init_status['loaded'],
            'initializing': _model_init_status['initializing'],
            'progress': _model_init_status['progress'],
            'progress_steps': _model_init_status['progress_steps'],
            'error': _model_init_status['error']
        }
    
    return jsonify({
        'success': True,
        'status': status
    })


@app.route('/api/diagnose/external-ai', methods=['GET'])
def diagnose_external_ai():
    """
    è¯Šæ–­å¤–éƒ¨AI APIè¿æ¥
    ç”¨äºæµ‹è¯•å¤–éƒ¨APIæ˜¯å¦å¯ç”¨
    """
    diagnosis = {
        'external_api_url': EXTERNAL_AI_BASE_URL,
        'external_api_model': EXTERNAL_AI_MODEL,
        'api_key_configured': bool(EXTERNAL_AI_API_KEY),
        'api_key_length': len(EXTERNAL_AI_API_KEY) if EXTERNAL_AI_API_KEY else 0,
        'tests': []
    }
    
    # æµ‹è¯•1: åŸºæœ¬è¿æ¥æµ‹è¯•
    test1 = {
        'name': 'åŸºæœ¬è¿æ¥æµ‹è¯•',
        'status': 'unknown',
        'details': {}
    }
    try:
        import socket
        from urllib.parse import urlparse
        parsed = urlparse(EXTERNAL_AI_BASE_URL)
        host = parsed.hostname
        port = parsed.port or (443 if parsed.scheme == 'https' else 80)
        
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(5)
        result = sock.connect_ex((host, port))
        sock.close()
        
        if result == 0:
            test1['status'] = 'success'
            test1['details'] = {'message': f'å¯ä»¥è¿æ¥åˆ° {host}:{port}'}
        else:
            test1['status'] = 'failed'
            test1['details'] = {'message': f'æ— æ³•è¿æ¥åˆ° {host}:{port}', 'error_code': result}
    except Exception as e:
        test1['status'] = 'failed'
        test1['details'] = {'message': 'è¿æ¥æµ‹è¯•å¤±è´¥', 'error': str(e)}
    
    diagnosis['tests'].append(test1)
    
    # æµ‹è¯•2: HTTPè¯·æ±‚æµ‹è¯•
    test2 = {
        'name': 'HTTPè¯·æ±‚æµ‹è¯•',
        'status': 'unknown',
        'details': {}
    }
    try:
        url = f"{EXTERNAL_AI_BASE_URL}/chat/completions"
        headers = {
            "Authorization": f"Bearer {EXTERNAL_AI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
        test_payload = {
            "model": EXTERNAL_AI_MODEL,
            "messages": [{"role": "user", "content": "test"}],
            "max_tokens": 10
        }
        
        response = requests.post(url, headers=headers, json=test_payload, timeout=10)
        
        test2['status'] = 'success' if response.status_code < 500 else 'failed'
        test2['details'] = {
            'http_status': response.status_code,
            'response_headers': dict(response.headers),
            'response_preview': response.text[:200] if response.text else None
        }
        
        if response.status_code == 503:
            test2['details']['message'] = 'æœåŠ¡ä¸å¯ç”¨ (503) - å¤–éƒ¨APIæœåŠ¡å¯èƒ½æ­£åœ¨ç»´æŠ¤æˆ–è¿‡è½½'
        elif response.status_code == 401:
            test2['details']['message'] = 'è®¤è¯å¤±è´¥ (401) - APIå¯†é’¥å¯èƒ½æ— æ•ˆ'
        elif response.status_code == 429:
            test2['details']['message'] = 'è¯·æ±‚é¢‘ç‡è¿‡é«˜ (429) - è¶…è¿‡äº†é€Ÿç‡é™åˆ¶'
        elif response.status_code >= 500:
            test2['details']['message'] = f'æœåŠ¡å™¨é”™è¯¯ ({response.status_code})'
        elif response.status_code == 200:
            test2['details']['message'] = 'APIå¯ç”¨ï¼Œè¿æ¥æ­£å¸¸'
        else:
            test2['details']['message'] = f'HTTPçŠ¶æ€ç : {response.status_code}'
            
    except requests.exceptions.Timeout:
        test2['status'] = 'failed'
        test2['details'] = {'message': 'è¯·æ±‚è¶…æ—¶ - å¤–éƒ¨APIå“åº”æ—¶é—´è¿‡é•¿'}
    except requests.exceptions.ConnectionError as e:
        test2['status'] = 'failed'
        test2['details'] = {'message': 'è¿æ¥é”™è¯¯', 'error': str(e)}
    except Exception as e:
        test2['status'] = 'failed'
        test2['details'] = {'message': 'è¯·æ±‚å¤±è´¥', 'error': str(e)}
    
    diagnosis['tests'].append(test2)
    
    # è®¡ç®—æ€»ä½“çŠ¶æ€
    all_success = all(test['status'] == 'success' for test in diagnosis['tests'])
    any_failed = any(test['status'] == 'failed' for test in diagnosis['tests'])
    
    if all_success:
        diagnosis['overall_status'] = 'healthy'
        diagnosis['message'] = 'å¤–éƒ¨AI APIè¿æ¥æ­£å¸¸'
    elif any_failed:
        diagnosis['overall_status'] = 'unhealthy'
        diagnosis['message'] = 'å¤–éƒ¨AI APIè¿æ¥å­˜åœ¨é—®é¢˜ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æµ‹è¯•ç»“æœ'
    else:
        diagnosis['overall_status'] = 'unknown'
        diagnosis['message'] = 'æ— æ³•ç¡®å®šå¤–éƒ¨AI APIçŠ¶æ€'
    
    return jsonify(diagnosis)


@app.route('/api/generate', methods=['POST'])
def generate():
    """ç”Ÿæˆå•æ¬¡å›å¤"""
    try:
        data = request.json
        prompt = data.get('prompt', '')
        max_tokens = data.get('max_new_tokens', 8192)  # é»˜è®¤å€¼æ”¹ä¸º8192ï¼ŒåŸºæœ¬æ— é™åˆ¶
        temperature = data.get('temperature', 0.6)
        top_p = data.get('top_p', 0.9)
        system_prompt = data.get('system_prompt')
        assistant_role = data.get('assistant_role')
        
        if not prompt:
            return jsonify({'error': 'promptå‚æ•°ä¸èƒ½ä¸ºç©º'}), 400
        
        model = get_model()
        if model is None:
            return jsonify({'error': 'æ¨¡å‹æœªåŠ è½½'}), 500
        
        response = model.generate(
            prompt=prompt,
            max_new_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            system_prompt=system_prompt,
            assistant_role=assistant_role
        )
        
        return jsonify({
            'response': response,
            'success': True
        })
    
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@app.route('/api/chat', methods=['POST'])
def chat():
    """å¯¹è¯ç”Ÿæˆï¼ˆå¸¦å†å²ï¼‰"""
    try:
        data = request.json
        messages = data.get('messages', [])
        max_tokens = data.get('max_new_tokens', 8192)  # é»˜è®¤å€¼æ”¹ä¸º8192ï¼ŒåŸºæœ¬æ— é™åˆ¶
        temperature = data.get('temperature', 0.6)
        top_p = data.get('top_p', 0.9)
        system_prompt = data.get('system_prompt')
        assistant_role = data.get('assistant_role')
        
        if not messages:
            return jsonify({'error': 'messageså‚æ•°ä¸èƒ½ä¸ºç©º'}), 400
        
        model = get_model()
        if model is None:
            return jsonify({'error': 'æ¨¡å‹æœªåŠ è½½'}), 500
        
        response = model.chat(
            messages=messages,
            max_new_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            system_prompt=system_prompt,
            assistant_role=assistant_role
        )
        
        return jsonify({
            'response': response,
            'success': True
        })
    
    except Exception as e:
        logger.error(f"å¯¹è¯ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@app.route('/api/debate/generate', methods=['POST'])
def debate_generate():
    """
    æ³•åº­è¾©è®ºç”Ÿæˆ
    æ”¯æŒä¸¤ç§è¾“å…¥æ ¼å¼ï¼š
    1. è®­ç»ƒæ•°æ®æ ¼å¼ï¼ˆæ¨èï¼‰ï¼š
       {
         "agent_role": "å®¡åˆ¤å‘˜",  // å½“å‰è¦å›å¤çš„è§’è‰²
         "background": "...",     // æ¡ˆä»¶èƒŒæ™¯
         "context": "...",        // å¯¹è¯å†å²ï¼ˆç”¨\nåˆ†éš”ï¼‰
         "role_to_reply": "è¾©æŠ¤äºº", // è¦å›å¤çš„è§’è‰²
         "instruction": "..."     // è§’è‰²æŒ‡ä»¤
       }
    2. æ—§æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰ï¼š
       {
         "user_identity": "plaintiff",
         "current_role": "judge",
         "messages": [...],
         "judge_type": "neutral",
         "case_description": "..."
       }
    """
    try:
        data = request.json
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè®­ç»ƒæ•°æ®æ ¼å¼
        if 'agent_role' in data or 'context' in data:
            # ä½¿ç”¨è®­ç»ƒæ•°æ®æ ¼å¼
            return debate_generate_training_format(data)
        else:
            # ä½¿ç”¨æ—§æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            return debate_generate_legacy_format(data)
    
    except Exception as e:
        logger.error(f"è¾©è®ºç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


def debate_generate_training_format(data):
    """
    ä½¿ç”¨è®­ç»ƒæ•°æ®æ ¼å¼ç”Ÿæˆå›å¤
    
    è¾“å…¥å­—æ®µè¯´æ˜ï¼š
    - agent_role: å½“å‰AIæ‰®æ¼”çš„è§’è‰²ï¼ˆå¦‚"å®¡åˆ¤å‘˜"ã€"å…¬è¯‰äºº"ã€"è¾©æŠ¤äºº"ç­‰ï¼‰
    - background: æ¡ˆä»¶èƒŒæ™¯ï¼ˆå‰é¢ä¿å­˜çš„æ¡ˆä»¶æè¿°ï¼‰
    - context: ä¸Šä¸‹æ–‡ï¼ˆå¯¹è¯å†å²ï¼Œç”¨\nåˆ†éš”ï¼‰
    - instruction: è§’è‰²æŒ‡ä»¤ï¼ˆåŒ…å«è¯‰è®¼ç­–ç•¥ã€æ³•å®˜ç±»å‹ç­‰ï¼‰
    - role_to_reply: è¦å›å¤çš„è§’è‰²ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸agent_roleç›¸åŒï¼‰
    """
    agent_role = data.get('agent_role')  # å½“å‰AIæ‰®æ¼”çš„è§’è‰²
    background = data.get('background', '')  # æ¡ˆä»¶èƒŒæ™¯ï¼ˆä»å‰é¢ä¿å­˜çš„æ¡ˆä»¶æè¿°è·å–ï¼‰
    context = data.get('context', '')  # ä¸Šä¸‹æ–‡ï¼ˆå¯¹è¯å†å²ï¼Œç”¨\nåˆ†éš”ï¼‰
    role_to_reply = data.get('role_to_reply', agent_role)  # è¦å›å¤çš„è§’è‰²ï¼ˆå¯é€‰ï¼‰
    instruction = data.get('instruction', '')  # è§’è‰²æŒ‡ä»¤ï¼ˆåŒ…å«è¯‰è®¼ç­–ç•¥ã€æ³•å®˜ç±»å‹ç­‰ï¼‰
    
    if not agent_role:
        return jsonify({'error': 'agent_roleå‚æ•°ä¸èƒ½ä¸ºç©º'}), 400
    
    logger.info(f"[è®­ç»ƒæ ¼å¼] agent_role={agent_role}, backgroundé•¿åº¦={len(background)}, contexté•¿åº¦={len(context)}, instructioné•¿åº¦={len(instruction)}")
    if instruction:
        logger.info(f"[è®­ç»ƒæ ¼å¼] instructioné¢„è§ˆ: {instruction[:200]}...")
    
    model = get_model()
    if model is None:
        return jsonify({'error': 'æ¨¡å‹æœªåŠ è½½'}), 500
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆåŸºäºè®­ç»ƒæ•°æ®æ ¼å¼ï¼‰
    system_prompt = build_system_prompt_from_training_format(
        agent_role=agent_role,
        background=background,
        instruction=instruction
    )
    logger.info(f"[è®­ç»ƒæ ¼å¼] ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}")
    
    # å°†contextè½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
    formatted_messages = format_context_to_messages(context)
    logger.info(f"[è®­ç»ƒæ ¼å¼] è½¬æ¢åçš„æ¶ˆæ¯æ•°é‡: {len(formatted_messages)}")
    if formatted_messages:
        logger.info(f"[è®­ç»ƒæ ¼å¼] ç¬¬ä¸€æ¡æ¶ˆæ¯é¢„è§ˆ: {formatted_messages[0].get('content', '')[:100]}...")
        logger.info(f"[è®­ç»ƒæ ¼å¼] æœ€åä¸€æ¡æ¶ˆæ¯é¢„è§ˆ: {formatted_messages[-1].get('content', '')[:100]}...")
    
    # ç”Ÿæˆå›å¤ï¼ˆç§»é™¤max_new_tokensé™åˆ¶ï¼Œä½¿ç”¨å¾ˆå¤§çš„å€¼ç¡®ä¿ç”Ÿæˆå®Œæ•´å†…å®¹ï¼‰
    response = model.chat(
        messages=formatted_messages,
        max_new_tokens=8192,  # è®¾ç½®ä¸ºå¾ˆå¤§çš„å€¼ï¼ŒåŸºæœ¬æ— é™åˆ¶
        temperature=0.6,
        top_p=0.9,
        system_prompt=system_prompt,
        assistant_role=agent_role
    )
    
    logger.info(f"[è®­ç»ƒæ ¼å¼] ç”Ÿæˆå›å¤é•¿åº¦: {len(response)}")
    logger.info(f"[è®­ç»ƒæ ¼å¼] ç”Ÿæˆå›å¤é¢„è§ˆ: {response[:200]}...")
    
    return jsonify({
        'code': 200,
        'data': response,
        'role': agent_role,
        'success': True
    })


def debate_generate_legacy_format(data):
    """ä½¿ç”¨æ—§æ ¼å¼ç”Ÿæˆå›å¤ï¼ˆå‘åå…¼å®¹ï¼‰"""
    user_identity = data.get('user_identity')  # 'plaintiff' æˆ– 'defendant'
    current_role = data.get('current_role')  # 'judge', 'plaintiff', 'defendant'
    messages = data.get('messages', [])  # å¯¹è¯å†å²
    judge_type = data.get('judge_type', 'neutral')  # æ³•å®˜ç±»å‹
    case_description = data.get('case_description', '')  # æ¡ˆä»¶æè¿°ï¼ˆç°åœ¨å¯èƒ½åŒ…å«å®Œæ•´çš„backgroundï¼‰
    check_mode = data.get('checkMode', False)  # æ˜¯å¦ä¸ºåˆ¤æ–­æ¨¡å¼
    prompt = data.get('prompt', '')  # ç‰¹æ®Šæç¤ºè¯ï¼ˆç”¨äºåˆ¤æ–­æ¨¡å¼ï¼‰
    is_first_judge_speech = data.get('isFirstJudgeSpeech', False)  # æ˜¯å¦ä¸ºé¦–æ¬¡æ³•å®˜å‘è¨€
    
    if not user_identity or not current_role:
        return jsonify({'error': 'user_identityå’Œcurrent_roleå‚æ•°ä¸èƒ½ä¸ºç©º'}), 400
    
    model = get_model()
    if model is None:
        return jsonify({'error': 'æ¨¡å‹æœªåŠ è½½'}), 500
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    # case_description ç°åœ¨å¯èƒ½åŒ…å«å®Œæ•´çš„backgroundï¼ˆèº«ä»½ä¿¡æ¯ã€æ–‡ä»¶åˆ—è¡¨ã€æ¡ˆä»¶æè¿°ã€è¯‰è®¼ç­–ç•¥ç­‰ï¼‰
    system_prompt = build_system_prompt(user_identity, current_role, judge_type, case_description)
    assistant_role = get_assistant_role_name(current_role)
    
    # æ„å»ºæ¶ˆæ¯å†å²
    formatted_messages = format_messages_for_ai(messages)
    
    # å¦‚æœæ˜¯åˆ¤æ–­æ¨¡å¼ä¸”æœ‰ç‰¹æ®Šæç¤ºè¯ï¼Œæ·»åŠ æç¤ºè¯
    if check_mode and prompt:
        formatted_messages.append({
            'role': 'user',
            'content': prompt
        })
    
    # ç”Ÿæˆå›å¤ï¼ˆç§»é™¤max_new_tokensé™åˆ¶ï¼Œä½¿ç”¨å¾ˆå¤§çš„å€¼ç¡®ä¿ç”Ÿæˆå®Œæ•´å†…å®¹ï¼‰
    response = model.chat(
        messages=formatted_messages,
        max_new_tokens=8192,  # è®¾ç½®ä¸ºå¾ˆå¤§çš„å€¼ï¼ŒåŸºæœ¬æ— é™åˆ¶
        temperature=0.6,
        top_p=0.9,
        system_prompt=system_prompt,
        assistant_role=assistant_role
    )
    
    logger.info(f"[æ—§æ ¼å¼] ç”Ÿæˆå›å¤é•¿åº¦: {len(response)}")
    logger.info(f"[æ—§æ ¼å¼] ç”Ÿæˆå›å¤é¢„è§ˆ: {response[:200]}...")
    
    return jsonify({
        'code': 200,
        'data': response,
        'role': current_role,
        'success': True
    })


def build_system_prompt_from_training_format(agent_role, background, instruction):
    """
    æ ¹æ®è®­ç»ƒæ•°æ®æ ¼å¼æ„å»ºç³»ç»Ÿæç¤ºè¯
    
    Args:
        agent_role: å½“å‰AIæ‰®æ¼”çš„è§’è‰²ï¼ˆå¦‚"å®¡åˆ¤å‘˜"ã€"å…¬è¯‰äºº"ã€"è¾©æŠ¤äºº"ç­‰ï¼‰
        background: æ¡ˆä»¶èƒŒæ™¯ï¼ˆå‰é¢ä¿å­˜çš„æ¡ˆä»¶æè¿°ï¼‰
        instruction: è§’è‰²æŒ‡ä»¤ï¼ˆåŒ…å«è¯‰è®¼ç­–ç•¥ã€æ³•å®˜ç±»å‹ç­‰ï¼‰
    """
    base_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ³•å¾‹ä»ä¸šè€…ï¼Œéœ€è¦æ ¹æ®è§’è‰²å®šä½å‚ä¸æ³•åº­è¾©è®ºã€‚\n\n"
    
    # 1. æ·»åŠ è§’è‰²å®šä¹‰
    role_definitions = {
        'å®¡åˆ¤å‘˜': 'è§’è‰²ï¼šå®¡åˆ¤å‘˜\nèŒè´£ï¼šä¸»æŒåº­å®¡ï¼Œå¼•å¯¼è¾©è®ºï¼Œç¡®ä¿ç¨‹åºå…¬æ­£',
        'å…¬è¯‰äºº': 'è§’è‰²ï¼šå…¬è¯‰äºº\nèŒè´£ï¼šä»£è¡¨å›½å®¶è¡Œä½¿å…¬è¯‰æƒï¼ŒæŒ‡æ§çŠ¯ç½ªäº‹å®ï¼Œå‡ºç¤ºå¹¶è´¨è¯è¯æ®',
        'è¾©æŠ¤äºº': 'è§’è‰²ï¼šè¾©æŠ¤äºº\nèŒè´£ï¼šç»´æŠ¤è¢«å‘Šäººçš„åˆæ³•æƒç›Šï¼Œé’ˆå¯¹æŒ‡æ§æå‡ºè¾©æŠ¤æ„è§å’Œåé©³',
        'åŸå‘Š': 'è§’è‰²ï¼šåŸå‘Šä»£ç†å¾‹å¸ˆ\nèŒè´£ï¼šä»£è¡¨åŸå‘Šç»´æŠ¤æƒç›Šï¼Œæå‡ºè¯‰è®¼è¯·æ±‚ï¼Œæä¾›è¯æ®å’Œç†ç”±',
        'è¢«å‘Š': 'è§’è‰²ï¼šè¢«å‘Šä»£ç†å¾‹å¸ˆ\nèŒè´£ï¼šä»£è¡¨è¢«å‘Šè¿›è¡Œè¾©æŠ¤ï¼Œåé©³åŸå‘ŠæŒ‡æ§ï¼Œç»´æŠ¤è¢«å‘Šæƒç›Š'
    }
    
    role_def = role_definitions.get(agent_role, f'è§’è‰²ï¼š{agent_role}')
    base_prompt += f"ã€è§’è‰²å®šä¹‰ã€‘\n{role_def}\n\n"
    
    # 2. æ·»åŠ æ¡ˆä»¶èƒŒæ™¯ï¼ˆä»å‰é¢ä¿å­˜çš„æ¡ˆä»¶æè¿°è·å–ï¼‰
    if background:
        base_prompt += f"ã€æ¡ˆä»¶èƒŒæ™¯ã€‘\n{background}\n\n"
    
    # 3. æ·»åŠ è§’è‰²æŒ‡ä»¤ï¼ˆinstructionå­—æ®µï¼ŒåŒ…å«è¯‰è®¼ç­–ç•¥ã€æ³•å®˜ç±»å‹ç­‰ï¼‰
    # è¿™æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†ï¼ŒåŒ…å«äº†å…·ä½“çš„ç­–ç•¥æŒ‡å¯¼å’Œè§’è‰²ç‰¹å¾
    if instruction:
        base_prompt += f"ã€è§’è‰²æŒ‡ä»¤ä¸ç­–ç•¥ã€‘\n{instruction}\n\n"
    else:
        # å¦‚æœæ²¡æœ‰æä¾›instructionï¼Œä½¿ç”¨é»˜è®¤æŒ‡ä»¤
        default_instructions = {
            'å®¡åˆ¤å‘˜': 'è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ï¼š\n1. ä¿æŒä¸­ç«‹ã€å®¢è§‚ã€å…¬æ­£çš„ç«‹åœº\n2. å¼•å¯¼åº­å®¡ç¨‹åºæœ‰åºè¿›è¡Œï¼Œæ§åˆ¶åº­å®¡èŠ‚å¥\n3. å¯¹äº‰è®®ç„¦ç‚¹è¿›è¡Œå½’çº³å’Œæ€»ç»“\n4. ç¡®ä¿å„æ–¹å……åˆ†è¡¨è¾¾æ„è§ï¼Œç»´æŠ¤åº­å®¡ç§©åº\n5. åŸºäºäº‹å®å’Œæ³•å¾‹è¿›è¡Œåˆ¤æ–­ï¼Œä¸åä¸å€š',
            'å…¬è¯‰äºº': 'è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ï¼š\n1. ä»£è¡¨å›½å®¶è¡Œä½¿å…¬è¯‰æƒï¼ŒæŒ‡æ§çŠ¯ç½ªäº‹å®\n2. å‡ºç¤ºå¹¶è´¨è¯è¯æ®ï¼Œè¯æ˜çŠ¯ç½ªæ„æˆè¦ä»¶\n3. å›åº”è¾©æ–¹æ„è§ï¼Œç»´æŠ¤æŒ‡æ§çš„åˆæ³•æ€§\n4. å›´ç»•äº‰è®®ç„¦ç‚¹ç»„ç»‡ä¸¾è¯è´¨è¯\n5. å¼ºè°ƒä¸»å®¢è§‚è¦ä»¶ä¸å› æœå…³ç³»ï¼Œçªå‡ºé‡åˆ‘æƒ…èŠ‚',
            'è¾©æŠ¤äºº': 'è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ï¼š\n1. ç»´æŠ¤è¢«å‘Šäººçš„åˆæ³•æƒç›Š\n2. é’ˆå¯¹æŒ‡æ§æå‡ºè¾©æŠ¤æ„è§å’Œåé©³\n3. æå‡ºæœ‰åˆ©äºè¢«å‘Šäººçš„è¯æ®å’Œäº‹å®\n4. è´¨ç–‘æ§æ–¹è¯æ®çš„åˆæ³•æ€§ã€çœŸå®æ€§ã€å…³è”æ€§\n5. ä¸ºè¢«å‘Šäººäº‰å–ä»è½»ã€å‡è½»æˆ–å…é™¤å¤„ç½š',
            'åŸå‘Š': 'è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ï¼š\n1. ä»£è¡¨åŸå‘Šç»´æŠ¤æƒç›Šï¼Œæå‡ºè¯‰è®¼è¯·æ±‚\n2. æä¾›è¯æ®å’Œç†ç”±æ”¯æŒè¯‰è®¼è¯·æ±‚\n3. å›åº”è¢«å‘Šçš„ç­”è¾©æ„è§\n4. å›´ç»•äº‰è®®ç„¦ç‚¹ç»„ç»‡ä¸¾è¯è´¨è¯\n5. å¼ºè°ƒäº‹å®å’Œæ³•å¾‹ä¾æ®',
            'è¢«å‘Š': 'è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚ï¼š\n1. ä»£è¡¨è¢«å‘Šè¿›è¡Œè¾©æŠ¤ï¼Œåé©³åŸå‘ŠæŒ‡æ§\n2. æå‡ºæœ‰åˆ©äºè¢«å‘Šçš„è¯æ®å’Œäº‹å®\n3. è´¨ç–‘åŸå‘Šè¯æ®çš„åˆæ³•æ€§ã€çœŸå®æ€§ã€å…³è”æ€§\n4. ç»´æŠ¤è¢«å‘Šæƒç›Š\n5. äº‰å–ä»è½»ã€å‡è½»æˆ–å…é™¤è´£ä»»'
        }
        default_instruction = default_instructions.get(agent_role, 'è¯·æ ¹æ®ä½ çš„è§’è‰²å®šä½ï¼Œåœ¨æ³•åº­è¾©è®ºä¸­ä¿æŒä¸“ä¸šä¸¥è°¨ã€‚')
        base_prompt += f"ã€è§’è‰²æŒ‡ä»¤ä¸ç­–ç•¥ã€‘\n{default_instruction}\n\n"
    
    # 4. æ·»åŠ é€šç”¨è¦æ±‚
    base_prompt += "ã€é€šç”¨è¦æ±‚ã€‘\n"
    base_prompt += "è¯·æ ¹æ®ä½ çš„è§’è‰²å®šä½ï¼Œåœ¨æ³•åº­è¾©è®ºä¸­ï¼š\n"
    base_prompt += "1. æ ¹æ®å¯¹è¯å†å²ç†è§£å½“å‰è¾©è®ºé˜¶æ®µå’Œç„¦ç‚¹\n"
    base_prompt += "2. æ ¹æ®è§’è‰²æ ‡è®°ï¼ˆå®¡åˆ¤å‘˜/å…¬è¯‰äºº/è¾©æŠ¤äºº/åŸå‘Š/è¢«å‘Šï¼‰åˆ‡æ¢ç›¸åº”çš„è¯­è¨€é£æ ¼\n"
    base_prompt += "3. éµå¾ªæ³•åº­è¾©è®ºçš„é€»è¾‘é¡ºåºå’Œç¨‹åºè§„èŒƒ\n"
    base_prompt += "4. åŸºäºäº‹å®å’Œæ³•å¾‹æ¡æ–‡è¿›è¡Œä¸“ä¸šè¾©è®º"
    
    return base_prompt


def format_context_to_messages(context):
    """
    å°†è®­ç»ƒæ•°æ®æ ¼å¼çš„contextï¼ˆç”¨\nåˆ†éš”çš„å¯¹è¯ï¼‰è½¬æ¢ä¸ºæ¶ˆæ¯æ ¼å¼
    
    è¾“å…¥æ ¼å¼ï¼š
    "å®¡åˆ¤å‘˜: ç°åœ¨å¼€åº­...\nå…¬è¯‰äºº: æ ¹æ®èµ·è¯‰ä¹¦...\nè¾©æŠ¤äºº: æˆ‘æ–¹è®¤ä¸º..."
    æˆ–
    "å®¡åˆ¤å‘˜ï¼šç°åœ¨å¼€åº­...\nå…¬è¯‰äººï¼šæ ¹æ®èµ·è¯‰ä¹¦...\nè¾©æŠ¤äººï¼šæˆ‘æ–¹è®¤ä¸º..."
    
    è¾“å‡ºæ ¼å¼ï¼š
    [
        {"role": "user", "content": "å®¡åˆ¤å‘˜ï¼šç°åœ¨å¼€åº­..."},
        {"role": "assistant", "content": "å…¬è¯‰äººï¼šæ ¹æ®èµ·è¯‰ä¹¦..."},
        {"role": "user", "content": "è¾©æŠ¤äººï¼šæˆ‘æ–¹è®¤ä¸º..."}
    ]
    """
    if not context:
        return []
    
    messages = []
    lines = context.strip().split('\n')
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
        
        # è§£æè§’è‰²å’Œå†…å®¹ï¼ˆæ”¯æŒè‹±æ–‡å†’å·:å’Œä¸­æ–‡å†’å·ï¼šï¼‰
        role_name = ''
        content = line
        
        # ä¼˜å…ˆåŒ¹é…ä¸­æ–‡å†’å·ï¼ˆæ›´å¸¸è§ï¼‰
        if 'ï¼š' in line:
            parts = line.split('ï¼š', 1)
            role_name = parts[0].strip()
            content = parts[1].strip() if len(parts) > 1 else ''
        elif ':' in line:
            # æ”¯æŒè‹±æ–‡å†’å·ï¼ˆè®­ç»ƒæ•°æ®æ ¼å¼ï¼‰
            parts = line.split(':', 1)
            role_name = parts[0].strip()
            content = parts[1].strip() if len(parts) > 1 else ''
        
        # ç¡®å®šæ¶ˆæ¯è§’è‰²ï¼ˆäº¤æ›¿ä½¿ç”¨userå’Œassistantï¼‰
        # ç¬¬ä¸€æ¡æ¶ˆæ¯é€šå¸¸æ˜¯userï¼Œåç»­äº¤æ›¿
        if i == 0:
            msg_role = 'user'
        else:
            # æ ¹æ®å‰ä¸€æ¡æ¶ˆæ¯çš„è§’è‰²å†³å®š
            prev_role = messages[-1].get('role', 'user')
            msg_role = 'assistant' if prev_role == 'user' else 'user'
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼ˆç»Ÿä¸€ä½¿ç”¨ä¸­æ–‡å†’å·ï¼‰
        if role_name:
            msg_content = f"{role_name}ï¼š{content}"
        else:
            msg_content = content
        
        messages.append({
            'role': msg_role,
            'content': msg_content
        })
    
    return messages


def build_system_prompt(user_identity, current_role, judge_type, case_description):
    """æ„å»ºç³»ç»Ÿæç¤ºè¯
    case_description ç°åœ¨å¯èƒ½åŒ…å«å®Œæ•´çš„backgroundï¼ˆèº«ä»½ä¿¡æ¯ã€æ–‡ä»¶åˆ—è¡¨ã€æ¡ˆä»¶æè¿°ã€è¯‰è®¼ç­–ç•¥ç­‰ï¼‰
    """
    base_prompt = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ³•å¾‹ä»ä¸šè€…ï¼Œéœ€è¦æ ¹æ®è§’è‰²å®šä½å‚ä¸æ³•åº­è¾©è®ºã€‚\n\n"
    
    if current_role == 'judge':
        # æ³•å®˜è§’è‰² - æ³•å®˜ç±»å‹ä¼šåŠ å…¥è§’è‰²æç¤ºè¯ä¸­
        judge_prompts = {
            'professional': 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šå‹æ³•å®˜ï¼Œè®²è¯ç®€æ´ï¼Œä¸šåŠ¡ç†Ÿç»ƒï¼Œåˆ¤å†³æœæ–­ã€‚',
            'strong': 'ä½ æ˜¯ä¸€ä½å¼ºåŠ¿å‹æ³•å®˜ï¼Œä¸“ä¸šèƒ½åŠ›å‡ºä¼—ï¼Œç»†èŠ‚èƒ½åŠ›å¼ºã€‚',
            'partial-plaintiff': 'ä½ æ˜¯ä¸€ä½åè¢’å‹æ³•å®˜ï¼Œä¹ æƒ¯å¯¹åŸå‘Šå®½å®¹ã€‚',
            'partial-defendant': 'ä½ æ˜¯ä¸€ä½åè¢’å‹æ³•å®˜ï¼Œä¹ æƒ¯å¯¹è¢«å‘Šå®½å®¹ã€‚',
            'neutral': 'ä½ æ˜¯ä¸€ä½ä¸­ç«‹å‹æ³•å®˜ï¼Œä¿æŒä¸­ç«‹ï¼Œæ³¨é‡ç¨‹åºå…¬æ­£ã€‚'
        }
        role_prompt = judge_prompts.get(judge_type, judge_prompts['neutral'])
        base_prompt += f"{role_prompt}\n\n"
        base_prompt += f"è§’è‰²å®šä¹‰ï¼š\n- è§’è‰²ï¼šå®¡åˆ¤å‘˜\n- èŒè´£ï¼šä¸»æŒåº­å®¡ï¼Œå¼•å¯¼è¾©è®ºï¼Œç¡®ä¿ç¨‹åºå…¬æ­£\n\n"
    elif current_role == 'plaintiff':
        # åŸå‘Šå¾‹å¸ˆè§’è‰²
        base_prompt += f"è§’è‰²å®šä¹‰ï¼š\n- è§’è‰²ï¼šåŸå‘Šä»£ç†å¾‹å¸ˆ\n- èŒè´£ï¼šä»£è¡¨åŸå‘Šç»´æŠ¤æƒç›Šï¼Œæå‡ºè¯‰è®¼è¯·æ±‚ï¼Œæä¾›è¯æ®å’Œç†ç”±\n\n"
    elif current_role == 'defendant':
        # è¢«å‘Šå¾‹å¸ˆè§’è‰²
        base_prompt += f"è§’è‰²å®šä¹‰ï¼š\n- è§’è‰²ï¼šè¢«å‘Šä»£ç†å¾‹å¸ˆ\n- èŒè´£ï¼šä»£è¡¨è¢«å‘Šè¿›è¡Œè¾©æŠ¤ï¼Œåé©³åŸå‘ŠæŒ‡æ§ï¼Œç»´æŠ¤è¢«å‘Šæƒç›Š\n\n"
    
    # case_description ç°åœ¨åŒ…å«å®Œæ•´çš„backgroundï¼ˆèº«ä»½ä¿¡æ¯ã€æ–‡ä»¶åˆ—è¡¨ã€æ¡ˆä»¶æè¿°ã€è¯‰è®¼ç­–ç•¥ç­‰ï¼‰
    # è¿™äº›ä¿¡æ¯åœ¨æ¯æ¬¡AIå›ç­”æ—¶éƒ½è¦èƒ½çœ‹åˆ°
    if case_description:
        base_prompt += f"{case_description}\n\n"
    
    base_prompt += "è¯·æ ¹æ®ä½ çš„è§’è‰²å®šä½ï¼Œåœ¨æ³•åº­è¾©è®ºä¸­ï¼š\n"
    base_prompt += "1. æ ¹æ®å¯¹è¯å†å²ç†è§£å½“å‰è¾©è®ºé˜¶æ®µå’Œç„¦ç‚¹\n"
    base_prompt += "2. æ ¹æ®è§’è‰²æ ‡è®°ï¼ˆå®¡åˆ¤å‘˜/åŸå‘Š/è¢«å‘Šï¼‰åˆ‡æ¢ç›¸åº”çš„è¯­è¨€é£æ ¼\n"
    base_prompt += "3. éµå¾ªæ³•åº­è¾©è®ºçš„é€»è¾‘é¡ºåºå’Œç¨‹åºè§„èŒƒ\n"
    base_prompt += "4. åŸºäºäº‹å®å’Œæ³•å¾‹æ¡æ–‡è¿›è¡Œä¸“ä¸šè¾©è®º"
    
    return base_prompt


def get_assistant_role_name(role):
    """è·å–åŠ©æ‰‹è§’è‰²åç§°"""
    role_map = {
        'judge': 'å®¡åˆ¤å‘˜',
        'plaintiff': 'åŸå‘Š',
        'defendant': 'è¢«å‘Š'
    }
    return role_map.get(role, 'å®¡åˆ¤å‘˜')


def format_messages_for_ai(messages):
    """å°†å‰ç«¯æ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸ºAIéœ€è¦çš„æ ¼å¼"""
    formatted = []
    for msg in messages:
        role = msg.get('role')
        text = msg.get('text', '')
        name = msg.get('name', '')
        
        # è½¬æ¢ä¸ºAIæ ¼å¼
        if role == 'judge':
            ai_role = 'user'
            content = f"å®¡åˆ¤å‘˜ï¼š{text}"
        elif role == 'plaintiff':
            ai_role = 'user' if len(formatted) == 0 or formatted[-1].get('role') != 'user' else 'assistant'
            content = f"åŸå‘Šï¼š{text}"
        elif role == 'defendant':
            ai_role = 'user' if len(formatted) == 0 or formatted[-1].get('role') != 'user' else 'assistant'
            content = f"è¢«å‘Šï¼š{text}"
        else:
            continue
        
        formatted.append({
            'role': ai_role,
            'content': content
        })
    
    return formatted


def call_external_ai(prompt, system_prompt=None, max_tokens=2000, max_retries=3):
    """
    è°ƒç”¨å¤–éƒ¨AI APIï¼ˆOpenAIå…¼å®¹æ¥å£ï¼‰
    
    Args:
        prompt: ç”¨æˆ·æç¤ºè¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
    
    Returns:
        AIç”Ÿæˆçš„æ–‡æœ¬
    """
    url = f"{EXTERNAL_AI_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {EXTERNAL_AI_API_KEY}",
        "Content-Type": "application/json"
    }
    
    messages = []
    if system_prompt:
        messages.append({
            "role": "system",
            "content": system_prompt
        })
    messages.append({
        "role": "user",
        "content": prompt
    })
    
    payload = {
        "model": EXTERNAL_AI_MODEL,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": 0.7
    }
    
    # è®°å½•è¯·æ±‚è¯¦æƒ…
    prompt_length = len(prompt)
    system_prompt_length = len(system_prompt) if system_prompt else 0
    total_messages_length = sum(len(str(msg.get("content", ""))) for msg in messages)
    
    logger.info("=" * 60)
    logger.info("è°ƒç”¨å¤–éƒ¨AI API - è¯·æ±‚è¯¦æƒ…")
    logger.info("=" * 60)
    logger.info(f"URL: {url}")
    logger.info(f"æ¨¡å‹: {EXTERNAL_AI_MODEL}")
    logger.info(f"ç”¨æˆ·æç¤ºè¯é•¿åº¦: {prompt_length} å­—ç¬¦")
    logger.info(f"ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {system_prompt_length} å­—ç¬¦")
    logger.info(f"æ¶ˆæ¯æ€»æ•°: {len(messages)}")
    logger.info(f"æ€»æ¶ˆæ¯å†…å®¹é•¿åº¦: {total_messages_length} å­—ç¬¦")
    logger.info(f"æœ€å¤§tokenæ•°: {max_tokens}")
    logger.info(f"æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")
    logger.info(f"APIå¯†é’¥å‰ç¼€: {EXTERNAL_AI_API_KEY[:10]}...{EXTERNAL_AI_API_KEY[-4:] if len(EXTERNAL_AI_API_KEY) > 14 else ''}")
    
    # é‡è¯•æœºåˆ¶
    import time
    last_exception = None
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                # æŒ‡æ•°é€€é¿ï¼šç¬¬1æ¬¡é‡è¯•ç­‰å¾…2ç§’ï¼Œç¬¬2æ¬¡ç­‰å¾…4ç§’ï¼Œç¬¬3æ¬¡ç­‰å¾…8ç§’
                wait_time = 2 ** attempt
                logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ï¼‰...")
                time.sleep(wait_time)
            
            # å¢åŠ è¶…æ—¶æ—¶é—´
            response = requests.post(
                url, 
                headers=headers, 
                json=payload, 
                timeout=90,  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°90ç§’
                verify=True  # ä¿æŒSSLéªŒè¯ï¼Œä½†å¦‚æœé‡åˆ°SSLé”™è¯¯ï¼Œä¼šåœ¨å¼‚å¸¸å¤„ç†ä¸­æä¾›å»ºè®®
            )
            
            # è®°å½•å“åº”è¯¦æƒ…
            status_code = response.status_code
            response_headers = dict(response.headers)
            
            logger.info("=" * 60)
            logger.info("å¤–éƒ¨AI API - å“åº”è¯¦æƒ…")
            logger.info("=" * 60)
            logger.info(f"HTTPçŠ¶æ€ç : {status_code}")
            logger.info(f"å“åº”å¤´: {response_headers}")
            
            # å°è¯•è¯»å–å’Œè§£æå“åº”ä½“
            api_error_info = None
            try:
                response_text = response.text
                response_length = len(response_text)
                logger.info(f"å“åº”ä½“é•¿åº¦: {response_length} å­—ç¬¦")
                
                # å¦‚æœå“åº”ä½“ä¸å¤ªé•¿ï¼Œè®°å½•å®Œæ•´å†…å®¹ï¼›å¦åˆ™åªè®°å½•å‰500å­—ç¬¦
                if response_length < 1000:
                    logger.info(f"å“åº”ä½“å†…å®¹: {response_text}")
                else:
                    logger.info(f"å“åº”ä½“é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰: {response_text[:500]}...")
                
                # å°è¯•è§£æJSON
                try:
                    response_json = response.json()
                    logger.info(f"å“åº”JSONè§£ææˆåŠŸ")
                    if "error" in response_json:
                        api_error_info = response_json.get('error')
                        if isinstance(api_error_info, dict):
                            error_code = api_error_info.get('code', '')
                            error_message = api_error_info.get('message', '')
                            error_type = api_error_info.get('type', '')
                            
                            logger.error("=" * 60)
                            logger.error("âŒ APIè¿”å›é”™è¯¯è¯¦æƒ…")
                            logger.error("=" * 60)
                            logger.error(f"é”™è¯¯ä»£ç : {error_code}")
                            logger.error(f"é”™è¯¯ç±»å‹: {error_type}")
                            logger.error(f"é”™è¯¯æ¶ˆæ¯: {error_message}")
                            
                            # é’ˆå¯¹ç‰¹å®šé”™è¯¯æä¾›è¯¦ç»†è¯Šæ–­
                            if error_code == 'model_not_found':
                                logger.error("")
                                logger.error("ğŸ” æ¨¡å‹æœªæ‰¾åˆ°é”™è¯¯åˆ†æï¼š")
                                logger.error(f"  è¯·æ±‚çš„æ¨¡å‹: {EXTERNAL_AI_MODEL}")
                                logger.error(f"  é”™è¯¯æ¶ˆæ¯: {error_message}")
                                logger.error("")
                                logger.error("å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š")
                                logger.error("1. æ¨¡å‹åç§°ä¸æ­£ç¡®")
                                logger.error("   - æ£€æŸ¥APIæœåŠ¡å•†æ–‡æ¡£ï¼Œç¡®è®¤æ­£ç¡®çš„æ¨¡å‹åç§°")
                                logger.error("   - å¯èƒ½éœ€è¦çš„åç§°ï¼šgpt-4o-mini, gpt-4o-mini-2024-08-06, gpt-4o-mini-2024-07-18 ç­‰")
                                logger.error("")
                                logger.error("2. æ¨¡å‹åœ¨æŒ‡å®šåˆ†ç»„ä¸‹ä¸å¯ç”¨")
                                logger.error("   - é”™è¯¯æ¶ˆæ¯æåˆ°'åˆ†ç»„ default ä¸‹æ¨¡å‹æ— å¯ç”¨æ¸ é“'")
                                logger.error("   - å¯èƒ½éœ€è¦ï¼š")
                                logger.error("     a) ä½¿ç”¨ä¸åŒçš„åˆ†ç»„åç§°")
                                logger.error("     b) åœ¨APIè¯·æ±‚ä¸­æŒ‡å®šåˆ†ç»„å‚æ•°")
                                logger.error("     c) è”ç³»APIæœåŠ¡å•†é…ç½®æ¨¡å‹æ¸ é“")
                                logger.error("")
                                logger.error("3. APIå¯†é’¥æƒé™é—®é¢˜")
                                logger.error("   - å½“å‰APIå¯†é’¥å¯èƒ½æ²¡æœ‰æƒé™ä½¿ç”¨è¯¥æ¨¡å‹")
                                logger.error("   - æ£€æŸ¥APIå¯†é’¥å¯¹åº”çš„è´¦æˆ·æ˜¯å¦æœ‰è¯¥æ¨¡å‹çš„è®¿é—®æƒé™")
                                logger.error("   - å¯èƒ½éœ€è¦å‡çº§è´¦æˆ·æˆ–è´­ä¹°æ¨¡å‹è®¿é—®æƒé™")
                                logger.error("")
                                logger.error("4. æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨")
                                logger.error("   - è¯¥æ¨¡å‹å¯èƒ½æš‚æ—¶ä¸‹æ¶æˆ–ç»´æŠ¤ä¸­")
                                logger.error("   - å°è¯•ä½¿ç”¨å…¶ä»–å¯ç”¨çš„æ¨¡å‹ï¼ˆå¦‚ gpt-3.5-turboï¼‰")
                                logger.error("=" * 60)
                            elif error_code == 'invalid_api_key':
                                logger.error("")
                                logger.error("ğŸ” APIå¯†é’¥æ— æ•ˆ")
                                logger.error("   - æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
                                logger.error("   - ç¡®è®¤APIå¯†é’¥æ˜¯å¦å·²è¿‡æœŸ")
                                logger.error("   - éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æƒé™è®¿é—®è¯¥æ¨¡å‹")
                                logger.error("=" * 60)
                            elif error_code == 'insufficient_quota':
                                logger.error("")
                                logger.error("ğŸ” é…é¢ä¸è¶³")
                                logger.error("   - è´¦æˆ·ä½™é¢ä¸è¶³")
                                logger.error("   - éœ€è¦å……å€¼æˆ–å‡çº§è´¦æˆ·")
                                logger.error("=" * 60)
                        else:
                            logger.error(f"APIè¿”å›é”™è¯¯ä¿¡æ¯: {api_error_info}")
                except:
                    logger.warning("å“åº”ä½“ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼")
            except Exception as e:
                logger.warning(f"è¯»å–å“åº”ä½“å¤±è´¥: {e}")
            
            # æ£€æŸ¥HTTPçŠ¶æ€ç 
            if status_code == 503:
                logger.error("=" * 60)
                logger.error("âŒ 503 Service Unavailable - æœåŠ¡ä¸å¯ç”¨")
                logger.error("=" * 60)
                
                # å¦‚æœAPIè¿”å›äº†å…·ä½“çš„é”™è¯¯ä¿¡æ¯ï¼Œä¼˜å…ˆæ˜¾ç¤º
                if api_error_info and isinstance(api_error_info, dict):
                    error_code = api_error_info.get('code', '')
                    if error_code == 'model_not_found':
                        # model_not_foundé”™è¯¯å·²ç»åœ¨ä¸Šé¢è¯¦ç»†å¤„ç†äº†ï¼Œè¿™é‡Œåªæ˜¾ç¤ºç®€è¦æç¤º
                        logger.error("æ³¨æ„ï¼šè™½ç„¶HTTPçŠ¶æ€ç æ˜¯503ï¼Œä½†å®é™…é”™è¯¯æ˜¯æ¨¡å‹æœªæ‰¾åˆ°")
                        logger.error("è¯·æŸ¥çœ‹ä¸Šé¢çš„è¯¦ç»†é”™è¯¯åˆ†æ")
                    else:
                        logger.error(f"APIé”™è¯¯ä»£ç : {error_code}")
                        logger.error(f"APIé”™è¯¯æ¶ˆæ¯: {api_error_info.get('message', '')}")
                else:
                    logger.error("å¯èƒ½çš„åŸå› ï¼š")
                    logger.error("1. å¤–éƒ¨APIæœåŠ¡æ­£åœ¨ç»´æŠ¤æˆ–å‡çº§")
                    logger.error("2. æœåŠ¡å™¨è¿‡è½½ï¼Œæ— æ³•å¤„ç†è¯·æ±‚")
                    logger.error("3. ç½‘ç»œè¿æ¥é—®é¢˜æˆ–DNSè§£æå¤±è´¥")
                    logger.error("4. APIæœåŠ¡æä¾›å•†ä¸´æ—¶æ•…éšœ")
                    logger.error("5. è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¢«é™æµ")
                    logger.error("")
                    logger.error("è¯Šæ–­å»ºè®®ï¼š")
                    logger.error("1. æ£€æŸ¥å¤–éƒ¨APIæœåŠ¡çŠ¶æ€é¡µé¢ï¼ˆå¦‚æœæœ‰ï¼‰")
                    logger.error("2. ä½¿ç”¨curlæˆ–postmanç›´æ¥æµ‹è¯•APIç«¯ç‚¹")
                    logger.error("3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒDNSè§£æ")
                    logger.error("4. ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•")
                    logger.error("5. è”ç³»APIæœåŠ¡æä¾›å•†ç¡®è®¤æœåŠ¡çŠ¶æ€")
                logger.error("=" * 60)
            elif status_code == 401:
                logger.error("âŒ 401 Unauthorized - è®¤è¯å¤±è´¥")
                logger.error("å¯èƒ½çš„åŸå› ï¼šAPIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
            elif status_code == 429:
                logger.error("âŒ 429 Too Many Requests - è¯·æ±‚é¢‘ç‡è¿‡é«˜")
                logger.error("å¯èƒ½çš„åŸå› ï¼šè¶…è¿‡äº†APIçš„é€Ÿç‡é™åˆ¶")
            elif status_code >= 500:
                logger.error(f"âŒ {status_code} Server Error - æœåŠ¡å™¨é”™è¯¯")
                logger.error("å¯èƒ½çš„åŸå› ï¼šå¤–éƒ¨APIæœåŠ¡å™¨å†…éƒ¨é”™è¯¯")
            
            response.raise_for_status()
            
            result = response.json()
            if "choices" in result and len(result["choices"]) > 0:
                content = result["choices"][0]["message"]["content"]
                logger.info(f"âœ… å¤–éƒ¨AI APIè°ƒç”¨æˆåŠŸï¼Œç”Ÿæˆäº† {len(content)} ä¸ªå­—ç¬¦")
                return content
            else:
                logger.error(f"âŒ å¤–éƒ¨AI APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}")
                raise ValueError("å¤–éƒ¨AI APIè¿”å›æ ¼å¼å¼‚å¸¸")
    
        except requests.exceptions.Timeout as e:
            last_exception = e
            error_str = str(e)
            logger.error("=" * 60)
            logger.error(f"âŒ è¯·æ±‚è¶…æ—¶ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ï¼‰")
            logger.error("=" * 60)
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_str}")
            logger.error("å¯èƒ½çš„åŸå› ï¼š")
            logger.error("1. ç½‘ç»œè¿æ¥æ…¢æˆ–ä¸ç¨³å®š")
            logger.error("2. å¤–éƒ¨APIå“åº”æ—¶é—´è¿‡é•¿")
            logger.error("3. è¯·æ±‚å†…å®¹è¿‡å¤§ï¼Œå¤„ç†æ—¶é—´è¿‡é•¿")
            logger.error("=" * 60)
            
            # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸
            if attempt == max_retries - 1:
                raise RuntimeError(f"è°ƒç”¨å¤–éƒ¨AI APIè¶…æ—¶ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {error_str}")
            # å¦åˆ™ç»§ç»­é‡è¯•
            continue
    
        except requests.exceptions.SSLError as e:
            last_exception = e
            error_str = str(e)
            logger.error("=" * 60)
            logger.error(f"âŒ SSLè¿æ¥é”™è¯¯ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ï¼‰")
            logger.error("=" * 60)
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_str}")
            logger.error("å¯èƒ½çš„åŸå› ï¼š")
            logger.error("1. SSLè¯ä¹¦éªŒè¯å¤±è´¥")
            logger.error("2. SSLæ¡æ‰‹è¿‡ç¨‹ä¸­è¿æ¥æ„å¤–ä¸­æ–­")
            logger.error("3. æœåŠ¡å™¨SSLé…ç½®é—®é¢˜")
            logger.error("4. ç½‘ç»œä¸ç¨³å®šå¯¼è‡´SSLè¿æ¥ä¸­æ–­")
            logger.error("5. é˜²ç«å¢™æˆ–ä»£ç†å¹²æ‰°SSLè¿æ¥")
            logger.error("")
            logger.error("è¯Šæ–­å»ºè®®ï¼š")
            logger.error("1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š")
            logger.error("2. æ£€æŸ¥é˜²ç«å¢™å’Œä»£ç†è®¾ç½®")
            logger.error("3. å°è¯•ä½¿ç”¨curlæµ‹è¯•APIç«¯ç‚¹")
            logger.error("4. è”ç³»APIæœåŠ¡æä¾›å•†ç¡®è®¤æœåŠ¡çŠ¶æ€")
            logger.error("=" * 60)
            
            # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸
            if attempt == max_retries - 1:
                raise RuntimeError(f"æ— æ³•è¿æ¥åˆ°å¤–éƒ¨AI APIï¼ˆSSLé”™è¯¯ï¼Œå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {error_str}")
            # å¦åˆ™ç»§ç»­é‡è¯•
            continue
            
        except requests.exceptions.ConnectionError as e:
            last_exception = e
            error_str = str(e)
            logger.error("=" * 60)
            logger.error(f"âŒ è¿æ¥é”™è¯¯ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ï¼‰")
            logger.error("=" * 60)
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_str}")
            logger.error("å¯èƒ½çš„åŸå› ï¼š")
            logger.error("1. æ— æ³•è¿æ¥åˆ°å¤–éƒ¨APIæœåŠ¡å™¨")
            logger.error("2. DNSè§£æå¤±è´¥")
            logger.error("3. é˜²ç«å¢™æˆ–ä»£ç†é˜»æ­¢è¿æ¥")
            logger.error("4. å¤–éƒ¨APIæœåŠ¡å™¨å·²å…³é—­")
            logger.error("=" * 60)
            
            # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸
            if attempt == max_retries - 1:
                raise RuntimeError(f"æ— æ³•è¿æ¥åˆ°å¤–éƒ¨AI APIï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {error_str}")
            # å¦åˆ™ç»§ç»­é‡è¯•
            continue
    
        except requests.exceptions.HTTPError as e:
            # HTTPé”™è¯¯ï¼ˆå¦‚500ã€503ç­‰ï¼‰é€šå¸¸ä¸éœ€è¦é‡è¯•ï¼Œç›´æ¥æŠ›å‡º
            error_str = str(e)
            status_code = getattr(e.response, 'status_code', None) if hasattr(e, 'response') else None
            if status_code:
                logger.error(f"âŒ HTTPé”™è¯¯: {error_str} (çŠ¶æ€ç : {status_code})")
                raise RuntimeError(f"è°ƒç”¨å¤–éƒ¨AI APIå¤±è´¥: HTTP {status_code} - {error_str}")
            else:
                logger.error(f"âŒ HTTPé”™è¯¯: {error_str}")
                raise RuntimeError(f"è°ƒç”¨å¤–éƒ¨AI APIå¤±è´¥: {error_str}")
        
        except requests.exceptions.RequestException as e:
            last_exception = e
            error_str = str(e)
            logger.error("=" * 60)
            logger.error(f"âŒ è¯·æ±‚å¼‚å¸¸ï¼ˆç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ï¼‰")
            logger.error("=" * 60)
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_str}")
            logger.error("=" * 60)
            
            # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸
            if attempt == max_retries - 1:
                raise RuntimeError(f"è°ƒç”¨å¤–éƒ¨AI APIå¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {error_str}")
            # å¦åˆ™ç»§ç»­é‡è¯•
            continue
        
        except Exception as e:
            # å…¶ä»–å¼‚å¸¸ï¼ˆå¦‚JSONè§£æé”™è¯¯ç­‰ï¼‰é€šå¸¸ä¸éœ€è¦é‡è¯•
            logger.error("=" * 60)
            logger.error("âŒ å¤„ç†å¤–éƒ¨AI APIå“åº”å¤±è´¥")
            logger.error("=" * 60)
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {e}")
            import traceback
            logger.error(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
            logger.error("=" * 60)
            raise RuntimeError(f"å¤„ç†å¤–éƒ¨AI APIå“åº”å¤±è´¥: {str(e)}")
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªå¼‚å¸¸
    if last_exception:
        raise RuntimeError(f"è°ƒç”¨å¤–éƒ¨AI APIå¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {str(last_exception)}")


@app.route('/api/case/summarize', methods=['POST'])
def summarize_case():
    """
    æ¡ˆä»¶èµ„æ–™è‡ªåŠ¨æ€»ç»“
    æ ¹æ®ä¸Šä¼ çš„æ–‡ä»¶ä¿¡æ¯ç”Ÿæˆæ¡ˆä»¶æè¿°
    æ”¯æŒæ–‡ä»¶å†…å®¹è¯»å–
    """
    try:
        data = request.json
        file_names = data.get('file_names', [])
        file_contents = data.get('file_contents', [])  # æ–‡ä»¶å†…å®¹åˆ—è¡¨
        identity = data.get('identity', '')  # 'plaintiff' æˆ– 'defendant'
        
        if not file_names:
            return jsonify({'error': 'file_nameså‚æ•°ä¸èƒ½ä¸ºç©º'}), 400
        
        # æ„å»ºæç¤ºè¯
        identity_text = "åŸå‘Š" if identity == "plaintiff" else "è¢«å‘Š"
        
        # å¦‚æœæœ‰æ–‡ä»¶å†…å®¹ï¼Œä½¿ç”¨æ–‡ä»¶å†…å®¹ï¼›å¦åˆ™åªä½¿ç”¨æ–‡ä»¶å
        if file_contents and len(file_contents) > 0:
            # ä½¿ç”¨æ–‡ä»¶å†…å®¹
            files_info = "\n\n".join(file_contents)
            user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹{identity_text}ä¸Šä¼ çš„æ¡ˆä»¶æ–‡ä»¶å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æ¡ˆä»¶æè¿°ï¼š

{files_info}

é‡è¦æç¤ºï¼š
1. å¦‚æœæ–‡ä»¶æ˜¯è¯•é¢˜ã€æ¡ˆä¾‹é¢˜ã€ç»ƒä¹ é¢˜ã€ç«èµ›é¢˜ç›®ç­‰ï¼Œè¯·æå–è¯•é¢˜ä¸­æè¿°çš„å®é™…æ¡ˆä»¶ä¿¡æ¯ï¼Œè€Œä¸æ˜¯æ€»ç»“è¯•é¢˜æœ¬èº«ï¼ˆå¦‚"è¿™æ˜¯XXç«èµ›çš„è¯•é¢˜"è¿™ç±»å…ƒä¿¡æ¯ï¼‰ã€‚
2. å¿½ç•¥æ–‡ä»¶çš„æ ‡é¢˜ã€æ³¨æ„äº‹é¡¹ã€æäº¤è¦æ±‚ç­‰éæ¡ˆä»¶äº‹å®çš„å†…å®¹ï¼Œä¸“æ³¨äºæå–æ¡ˆä»¶æœ¬èº«çš„ä¿¡æ¯ã€‚
3. æå–æ¡ˆä»¶ä¸­çš„å½“äº‹äººã€äº‹ä»¶ç»è¿‡ã€æ—¶é—´ã€åœ°ç‚¹ã€äº‰è®®ç„¦ç‚¹ç­‰å®é™…æ¡ˆä»¶è¦ç´ ã€‚
4. å¦‚æœæ–‡ä»¶ä¸­åŒ…å«å¤šä¸ªæ¡ˆä»¶ï¼Œè¯·æ€»ç»“æ‰€æœ‰æ¡ˆä»¶ï¼›å¦‚æœåªæœ‰ä¸€ä¸ªæ¡ˆä»¶ï¼Œè¯·è¯¦ç»†æ€»ç»“è¯¥æ¡ˆä»¶ã€‚

è¯·ä»”ç»†åˆ†æä¸Šè¿°æ–‡ä»¶å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„æ¡ˆä»¶æè¿°ã€‚"""
        else:
            # åªæœ‰æ–‡ä»¶åï¼Œä½¿ç”¨æ–‡ä»¶ååˆ—è¡¨
            file_list_text = "\n".join([f"- {name}" for name in file_names])
            user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹{identity_text}ä¸Šä¼ çš„æ¡ˆä»¶æ–‡ä»¶ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„æ¡ˆä»¶æè¿°ï¼š

æ–‡ä»¶åˆ—è¡¨ï¼š
{file_list_text}

è¯·åŸºäºè¿™äº›æ–‡ä»¶ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„æ¡ˆä»¶æè¿°ã€‚å¦‚æœæ— æ³•ä»æ–‡ä»¶åæ¨æ–­å…·ä½“å†…å®¹ï¼Œè¯·æ ¹æ®å¸¸è§çš„æ¡ˆä»¶ç±»å‹å’Œæ–‡ä»¶ç±»å‹è¿›è¡Œåˆç†æ¨æµ‹ï¼Œç”Ÿæˆä¸€ä»½ç¬¦åˆæ³•å¾‹è§„èŒƒçš„æ¡ˆä»¶æè¿°ã€‚"""
        
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ³•å¾‹åŠ©ç†ï¼Œæ“…é•¿åˆ†æå’Œæ€»ç»“æ¡ˆä»¶èµ„æ–™ã€‚è¯·æ ¹æ®æä¾›çš„æ–‡ä»¶ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æ¡ˆä»¶æè¿°ã€‚

é‡è¦åŸåˆ™ï¼š
1. å¦‚æœæ–‡ä»¶æ˜¯è¯•é¢˜ã€æ¡ˆä¾‹é¢˜ã€ç»ƒä¹ é¢˜ç­‰ï¼Œå¿…é¡»æå–è¯•é¢˜ä¸­æè¿°çš„å®é™…æ¡ˆä»¶ä¿¡æ¯ï¼Œè€Œä¸æ˜¯æ€»ç»“è¯•é¢˜çš„æ ¼å¼ã€è¦æ±‚ç­‰å…ƒä¿¡æ¯ã€‚
2. å¿½ç•¥æ–‡ä»¶çš„æ ‡é¢˜ã€æ³¨æ„äº‹é¡¹ã€æäº¤è¦æ±‚ã€æ ¼å¼è¦æ±‚ç­‰éæ¡ˆä»¶äº‹å®çš„å†…å®¹ã€‚
3. ä¸“æ³¨äºæå–æ–‡ä»¶ä¸­æè¿°çš„å®é™…æ¡ˆä»¶ï¼šå½“äº‹äººå§“åã€äº‹ä»¶ç»è¿‡ã€æ—¶é—´ã€åœ°ç‚¹ã€äº‰è®®äº‹å®ç­‰ã€‚

è¦æ±‚ï¼š
1. åˆ†ææ¡ˆä»¶çš„åŸºæœ¬æƒ…å†µï¼ˆå½“äº‹äººã€æ¡ˆç”±ã€æ—¶é—´ç­‰ï¼‰
2. è¯†åˆ«äº‰è®®ç„¦ç‚¹
3. åˆ—å‡ºç›¸å…³æ³•æ¡ï¼ˆæ ¹æ®æ¡ˆä»¶ç±»å‹ï¼Œå¦‚åˆ‘äº‹æ¡ˆä»¶ã€æ°‘äº‹æ¡ˆä»¶ç­‰ï¼‰
4. æå–æ¡ˆä»¶å…³é”®è¦ç´ ï¼ˆå½“äº‹äººå…³ç³»ã€äº‹ä»¶ç»è¿‡ã€æ—¶é—´èŠ‚ç‚¹ã€åœ°ç‚¹ã€è¯æ®ç­‰ï¼‰
5. ä½¿ç”¨æ¸…æ™°çš„ç»“æ„å’Œä¸“ä¸šçš„æ³•å¾‹æœ¯è¯­

è¾“å‡ºæ ¼å¼ï¼š
æ¡ˆä»¶åŸºæœ¬æƒ…å†µï¼š
[æ¡ˆä»¶åŸºæœ¬æƒ…å†µæè¿°ï¼ŒåŒ…æ‹¬å½“äº‹äººã€æ¡ˆç”±ã€æ—¶é—´ã€åœ°ç‚¹ç­‰]

äº‰è®®ç„¦ç‚¹ï¼š
1. [ç„¦ç‚¹1]
2. [ç„¦ç‚¹2]
...

ç›¸å…³æ³•æ¡ï¼š
[ç›¸å…³æ³•æ¡å¼•ç”¨ï¼Œæ ¹æ®æ¡ˆä»¶ç±»å‹é€‰æ‹©ï¼Œå¦‚åˆ‘æ³•ã€æ°‘æ³•ã€è¯‰è®¼æ³•ç­‰]

æ¡ˆä»¶è¦ç´ ï¼š
- [è¦ç´ 1]
- [è¦ç´ 2]
..."""
        
        # è°ƒç”¨å¤–éƒ¨AI API
        summary = call_external_ai(user_prompt, system_prompt, max_tokens=2000)
        
        return jsonify({
            'summary': summary,
            'success': True
        })
    
    except Exception as e:
        logger.error(f"æ¡ˆä»¶æ€»ç»“å¤±è´¥: {e}")
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@app.route('/api/verdict/generate', methods=['POST'])
def generate_verdict():
    """
    åº­åå®£åˆ¤ - ç”Ÿæˆåˆ¤å†³ä¹¦
    æ ¹æ®æ¡ˆä»¶ä¿¡æ¯å’Œåº­å®¡å¯¹è¯å†å²ç”Ÿæˆåˆ¤å†³ä¹¦
    """
    try:
        data = request.json
        case_description = data.get('case_description', '')
        messages = data.get('messages', [])  # åº­å®¡å¯¹è¯å†å²
        identity = data.get('identity', '')  # ç”¨æˆ·èº«ä»½
        
        if not case_description:
            return jsonify({'error': 'case_descriptionå‚æ•°ä¸èƒ½ä¸ºç©º'}), 400
        
        # æ„å»ºåº­å®¡å¯¹è¯æ‘˜è¦
        dialogue_summary = ""
        if messages:
            dialogue_summary = "\n".join([
                f"{msg.get('name', '')}ï¼š{msg.get('text', '')}" 
                for msg in messages 
                if msg.get('text')
            ])
        
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ³•å®˜ï¼Œéœ€è¦æ ¹æ®æ¡ˆä»¶ä¿¡æ¯å’Œåº­å®¡å¯¹è¯å†å²ï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„æ°‘äº‹åˆ¤å†³ä¹¦ã€‚

åˆ¤å†³ä¹¦åº”åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
1. æ¡ˆä»¶åŸºæœ¬ä¿¡æ¯ï¼ˆå½“äº‹äººä¿¡æ¯ã€æ¡ˆç”±ã€æ¡ˆä»¶ç¼–å·ã€å®¡ç†æ³•é™¢ã€å®¡ç†æ—¶é—´ç­‰ï¼‰
2. å®¡ç†ç»è¿‡ï¼ˆèµ·è¯‰æ—¶é—´å’Œäº‹å®ã€å®¡ç†è¿‡ç¨‹æ¦‚è¿°ã€å½“äº‹äººä¸»è¦äº‰è®®ç‚¹ï¼‰
3. å½“äº‹äººè¯‰è®¼è¯·æ±‚å’Œç­”è¾©ï¼ˆåŸå‘Šè¯‰è®¼è¯·æ±‚ã€è¢«å‘Šçš„ç­”è¾©æ„è§ã€äº‰è®®çš„ä¸»è¦é—®é¢˜ï¼‰
4. æœ¬é™¢æŸ¥æ˜çš„äº‹å®ï¼ˆåŸºäºæ¡ˆä»¶æè¿°å’Œåº­å®¡å¯¹è¯ï¼‰
5. æœ¬é™¢è®¤ä¸ºï¼ˆæ³•å¾‹é€‚ç”¨åˆ†æã€å¯¹äº‰è®®é—®é¢˜çš„æ³•å¾‹åˆ¤æ–­ã€è´£ä»»è®¤å®šå’Œç†ç”±ï¼‰

è¦æ±‚ï¼š
- ä½¿ç”¨æ­£å¼çš„æ³•å¾‹æ–‡ä¹¦æ ¼å¼
- è¯­è¨€ä¸¥è°¨ã€ä¸“ä¸š
- åŸºäºæä¾›çš„æ¡ˆä»¶ä¿¡æ¯å’Œåº­å®¡å¯¹è¯è¿›è¡Œåˆç†æ¨æ–­
- åˆ¤å†³ä¹¦åº”å®Œæ•´ã€é€»è¾‘æ¸…æ™°"""
        
        user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æ¡ˆä»¶ä¿¡æ¯å’Œåº­å®¡å¯¹è¯ï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„æ°‘äº‹åˆ¤å†³ä¹¦ï¼š

æ¡ˆä»¶æè¿°ï¼š
{case_description}

åº­å®¡å¯¹è¯å†å²ï¼š
{dialogue_summary if dialogue_summary else "ï¼ˆæ— è¯¦ç»†å¯¹è¯è®°å½•ï¼‰"}

è¯·ç”Ÿæˆä¸€ä»½å®Œæ•´çš„æ°‘äº‹åˆ¤å†³ä¹¦ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„éƒ¨åˆ†ã€‚"""
        
        # è°ƒç”¨å¤–éƒ¨AI API
        verdict = call_external_ai(user_prompt, system_prompt, max_tokens=4000)
        
        return jsonify({
            'verdict': verdict,
            'success': True
        })
    
    except Exception as e:
        logger.error(f"åˆ¤å†³ä¹¦ç”Ÿæˆå¤±è´¥: {e}")
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('DEBUG', 'false').lower() == 'true'
    
    logger.info(f"å¯åŠ¨AIæœåŠ¡ï¼Œç«¯å£: {port}")
    app.run(host='0.0.0.0', port=port, debug=debug)

